---
title: Challenge Guidelines
layout: default
filename: challenge.md
---

## Challenge Guidelines

As part of the benchmarking effort, we are hosting a competition and offering prizes for the best-performing submissions on the EvalAI leaderboard. The challenge deadline is **XXX**. The challenge is hosted on [EvalAI](https://eval.ai/web/challenges/challenge-page/1256/overview).

### Ranking and Prizes

Metric decisions, aggregations.
The prizes are allocated as follows:
- A prize of 1,000 USD will be given for best rank on each of `MC_Maze`, `MC_RTT`, `Area2_Bump`, and `DMFC_RSG`.
- A prize of 1,000 USD will be given for best average rank on `MC_Maze-Large`, `MC_Maze-Medium`, and `MC_Maze-Small`.
Prizes will be provided in the form of Visa gift cards.

### Eligibility

To be considered for challenge prizes, teams must submit their methods to the EvalAI challenge before the deadline *and* commit to releasing training code for reproducibility. (There is no commitment to release training data.) Code must be open-sourced before we transfer funds.
Note that NLB organizers are ineligible for collecting prize money.

We recommend participants to publicly share their code to help promote progress in the field.


